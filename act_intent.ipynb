{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 90)\n",
      "[ 0.29323264  0.04613507  0.03517929  0.04042785  0.01994394  0.\n",
      "  0.05581112  0.05795737  0.0562305   0.01881537  1.48317494  1.827599\n",
      "  1.50379333  1.49925482  1.53546079]\n",
      "(45, 15)\n",
      "[ 0.18194976  0.22943016 -0.0155392  -0.00513664 -0.041792   -0.0188544\n",
      " -0.00543104 -0.02668416 -0.022272   -0.00312064 -0.0401664  -0.0033664\n",
      " -0.00354304 -0.01925248  0.0038144   0.          0.          0.\n",
      " -0.00715264 -0.04341888 -0.0343296  -0.0113152  -0.02518784 -0.0509568\n",
      " -0.00731648 -0.00615936 -0.0554112  -0.0044416  -0.01056128 -0.0149248\n",
      " -0.00275328  0.01945344  1.4830448   0.19873976  1.04938016  1.4830448\n",
      "  0.16521976  0.56901016  1.3821448   0.16594976  0.79372016  1.2610448\n",
      "  0.16664976  1.00978016  1.1446448 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "import matplotlib.animation as animation\n",
    "# Attaching 3D axis to the figure\n",
    "import os\n",
    "\n",
    "#preprocess\n",
    "def get_video(src_file):\n",
    "    video = src_file.read().splitlines()\n",
    "    # video[:,3,6,9...]\n",
    "    for i in range(len(video)):\n",
    "        frame = video[i].split(',')[1:]#escape the first number\n",
    "        frame = [float(j) for j in frame] # turn them into float\n",
    "        video[i] = frame\n",
    "        \n",
    "    video = np.array(video)\n",
    "    for i in range(video.shape[1]/3):\n",
    "        video[:,i+2] = video[:,i+2]/7.8125\n",
    "    return video\n",
    "\n",
    "def get_subject_video(video,subject):\n",
    "    return video[:,subject*45:subject*45+45]\n",
    "\n",
    "\n",
    "def get_act_subject(video):\n",
    "    subject_dist = list()\n",
    "    for subject in [0,1]:\n",
    "        total_dist = 0\n",
    "        s_video = get_subject_video(video,subject)\n",
    "        for i in range(1,len(video)):\n",
    "            # print i\n",
    "            total_dist = total_dist + vect_length(s_video[i,:]-s_video[i-1,:])\n",
    "        subject_dist.append(total_dist)    \n",
    "    if subject_dist[0]>subject_dist[1]:\n",
    "        act_subject = 0\n",
    "    else :\n",
    "        act_subject = 1\n",
    "    return act_subject\n",
    "\n",
    "\n",
    "def divide_video(video):\n",
    "    act_subject = get_act_subject(video)\n",
    "    react_subject = 1-act_subject\n",
    "    act_video = get_subject_video(video, act_subject)\n",
    "    react_video = get_subject_video(video, react_subject)\n",
    "    return act_video, react_video\n",
    "\n",
    "def vect_length(vect):\n",
    "    return np.dot(vect,vect)**0.5\n",
    "\n",
    "def dist_from_joints_to_joint(joints,joint):\n",
    "    # assume joints is (x1,y1,z1,x2,y2,z2,...)\n",
    "    joints_num = len(joints)/3\n",
    "    \n",
    "    dist_list = np.zeros(joints_num)\n",
    "    for i in range(joints_num):\n",
    "        vect = get_joint(joints,i)-joint\n",
    "        dist_list[i] = vect_length(vect)\n",
    "    return dist_list\n",
    "\n",
    "def pos_from_joints_to_joint(joints,joint):\n",
    "    temp = np.array([])\n",
    "    for i in range(len(joints)/3):\n",
    "        temp = np.append(temp,joint)\n",
    "    return joints-temp\n",
    "\n",
    "def dist_from_video_to_joint(video,joint):\n",
    "    dist_mat = np.array([])\n",
    "    for i in range(len(video)):\n",
    "        dist_list = dist_from_joints_to_joint(video[i,:], joint)\n",
    "        dist_mat = np.vstack((dist_mat, dist_list)) if dist_mat.size else dist_list\n",
    "    return dist_mat\n",
    "\n",
    "def get_joint(video,joint):\n",
    "    if len(video.shape)==1: #only a frame\n",
    "        return video[3*joint:3*joint+3]\n",
    "    else:\n",
    "        return video[:, 3*joint:3*joint+3]\n",
    "\n",
    "\n",
    "path = 'sbu_cleaned/01/s01s02001.txt'\n",
    "with open(path,'r') as src_file:\n",
    "    video = get_video(src_file)\n",
    "    print video.shape\n",
    "    act_video, react_video = divide_video(video)\n",
    "    \n",
    "    joint = get_joint(react_video[1,:],5)\n",
    "    joints = react_video[1,:]\n",
    "    \n",
    "    print dist_from_joints_to_joint(joints, joint)\n",
    "    \n",
    "    print dist_from_video_to_joint(act_video,joint).shape\n",
    "    \n",
    "    print pos_from_joints_to_joint(joints, joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22,)\n",
      "(22, 180)\n"
     ]
    }
   ],
   "source": [
    "# DONE Procesing in each directory of action class\n",
    "# Find a subject as the first action\n",
    "\n",
    "ALLOWED_EXTENSIONS=set(['txt'])\n",
    "\n",
    "def allowed_files(filename):\n",
    "    return '.' in filename and filename.rsplit('.',1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "\n",
    "\n",
    "TORSO = 2\n",
    "\n",
    "\n",
    "def joint_intent_extract(path, joint, subact_length, show_fag=False):\n",
    "    with open(path,'r') as src_file:\n",
    "        video = get_video(src_file)\n",
    "        act_video, react_video = divide_video(video)\n",
    "        \n",
    "        # torso positions\n",
    "        act_torso = get_joint(act_video[0,:], TORSO)\n",
    "        react_torso = get_joint(react_video[0,:],TORSO)\n",
    "\n",
    "        act_joint_video = get_joint(act_video, joint)\n",
    "        react_joint_video = get_joint(react_video, joint)\n",
    "        # compare the target_points with the dist \n",
    "        \n",
    "        \n",
    "        act_to_react_torso = dist_from_video_to_joint(act_joint_video,react_torso)\n",
    "        react_to_act_torso = dist_from_video_to_joint(react_joint_video,act_torso)\n",
    "               \n",
    "        labels = np.array([])   \n",
    "        for i in range(subact_length,len(video)):\n",
    "            react_movement = react_to_act_torso[i] - react_to_act_torso[i-subact_length]\n",
    "            act_movement = act_to_react_torso[i] - act_to_react_torso[i-subact_length]\n",
    "            \n",
    "            if react_movement>0:\n",
    "                # intend to leave\n",
    "                label = 2\n",
    "            else:\n",
    "                # intend to reach\n",
    "                label = 1\n",
    "            \n",
    "            if abs(act_movement)>abs(react_movement*2):\n",
    "                label = 0 # no intent\n",
    "            \n",
    "            labels = np.append(labels,label)\n",
    "\n",
    "    return labels\n",
    "\n",
    "def skel_feature_extract(path, subact_length):\n",
    "    with open(path,'r') as src_file:\n",
    "        video = get_video(src_file)\n",
    "        act_video, react_video = divide_video(video)\n",
    "        \n",
    "        # torso positions\n",
    "        act_torso = get_joint(act_video[0,:], TORSO)\n",
    "        react_torso = get_joint(react_video[0,:],TORSO)\n",
    "        \n",
    "        dist_react_torso = dist_from_video_to_joint(act_video, react_torso)\n",
    "        dist_act_torso = dist_from_video_to_joint(act_video, act_torso)\n",
    "        \n",
    "        \n",
    "        # distance feature\n",
    "        feat0 = dist_act_torso[subact_length:]\n",
    "        # distance feature\n",
    "        feat1 = dist_react_torso[subact_length:]\n",
    "        \n",
    "        # distance velocity feature\n",
    "        feat2 = np.array([])\n",
    "        for i in range(subact_length,len(video)):\n",
    "            temp = np.array([])\n",
    "            for d in range(1,1+subact_length):\n",
    "                temp = np.append(temp, dist_react_torso[i] - dist_react_torso[i-d])\n",
    "            feat2 = np.vstack((feat2,temp)) if feat2.size else temp\n",
    "               \n",
    "        # distance velocity feature\n",
    "        feat4 = np.array([])\n",
    "        for i in range(subact_length,len(video)):\n",
    "            temp = np.array([])\n",
    "            for d in range(1,1+subact_length):\n",
    "                temp = np.append(temp, dist_act_torso[i] - dist_act_torso[i-d])\n",
    "            feat4 = np.vstack((feat4,temp)) if feat4.size else temp\n",
    "               \n",
    "        \n",
    "        # velocity feature \n",
    "        feat3 = np.array([])\n",
    "        for i in range(subact_length, len(video)):\n",
    "            temp = np.array([])\n",
    "            for d in range(1,1+subact_length):\n",
    "                temp = np.append(temp, act_video[i] - act_video[i-d])\n",
    "            feat3 = np.vstack((feat3, temp)) if feat3.size else temp\n",
    "        \n",
    "        # position feature\n",
    "        feat5 = np.array([])\n",
    "        for i in range(subact_length, len(video)):\n",
    "            temp = act_video\n",
    "            feat5 = np.vstack()\n",
    "        \n",
    "        # vector of each \n",
    "        feat = np.hstack((feat0, feat1, feat2, feat3, feat4))\n",
    "        \n",
    "    return feat\n",
    "\n",
    "\n",
    "path = 'sbu_cleaned/01/s01s02002.txt'\n",
    "labels = joint_intent_extract(path, TORSO, 2)\n",
    "print labels.shape\n",
    "\n",
    "feat = skel_feature_extract(path,2)\n",
    "print feat.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(902, 180)\n",
      "(902,)\n"
     ]
    }
   ],
   "source": [
    "def build_data_set(target_folder, joint_ind, subact_length, show_fag = False):\n",
    "    class_lib = list()\n",
    "    for root,dirs,files in os.walk(target_folder):\n",
    "        for f in files:\n",
    "            path = os.path.join(root,f)\n",
    "            if allowed_files(path):\n",
    "                class_lib.append(path)\n",
    "\n",
    "    tt_labels = np.array([])\n",
    "    tt_feat = np.array([])\n",
    "    \n",
    "    for path in class_lib:\n",
    "        if show_fag:\n",
    "            print path,\n",
    "        \n",
    "        labels = joint_intent_extract(path,joint_ind, subact_length, show_fag)\n",
    "        tt_labels = np.append(tt_labels, labels)\n",
    "\n",
    "        feat = skel_feature_extract(path, subact_length)\n",
    "        \n",
    "        tt_feat = np.vstack((tt_feat,feat)) if tt_feat.size else feat\n",
    "        \n",
    "    return tt_feat, tt_labels\n",
    "\n",
    "\n",
    "\n",
    "def divide_data_set(act_dict,react_dict,train_rate=0.8):\n",
    "    react_dict = react_dict.astype('int')\n",
    "    train_size = int(act_dict.shape[0]*train_rate)\n",
    "\n",
    "    selected_indices = np.unique(np.random.choice(act_dict.shape[0],train_size,replace=False))\n",
    "    \n",
    "    all_indices = range(act_dict.shape[0])\n",
    "    rest_indices = set(all_indices).difference(selected_indices)\n",
    "    \n",
    "    rest_indices = list(rest_indices)\n",
    "    selected_indices = list(selected_indices)\n",
    "    \n",
    "    training_samples = act_dict[selected_indices]\n",
    "    training_ground = react_dict[selected_indices]\n",
    "    test_samples = act_dict[rest_indices]\n",
    "    test_ground = react_dict[rest_indices]\n",
    "\n",
    "    return training_samples, training_ground, test_samples, test_ground\n",
    "\n",
    "    #print \"count direction error:\", count_error,'/',sum(test_results<>test_ground)\n",
    "\n",
    "folder = \"sbu_cleaned/01/\"\n",
    "feats, labels = build_data_set(folder, joint_ind=2 , subact_length=2)\n",
    "print feats.shape\n",
    "print labels.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(734, 480) (734,)\n",
      "all: 734 train: 587 test: 147\n",
      "(520, 480) (520,)\n",
      "all: 520 train: 416 test: 104\n",
      "(607, 480) (607,)\n",
      "all: 607 train: 485 test: 122\n",
      "(895, 480) (895,)\n",
      "all: 895 train: 716 test: 179\n",
      "(494, 480) (494,)\n",
      "all: 494 train: 395 test: 99\n",
      "(517, 480) (517,)\n",
      "all: 517 train: 413 test: 104\n",
      "(750, 480) (750,)\n",
      "all: 750 train: 600 test: 150\n",
      "(613, 480) (613,)\n",
      "all: 613 train: 490 test: 123\n"
     ]
    }
   ],
   "source": [
    "def random_precision(labels):    \n",
    "    tt_proportion = []\n",
    "    for i in np.unique(labels):\n",
    "        proportion = sum(labels==i)/float(len(labels))\n",
    "        tt_proportion.extend([proportion])\n",
    "    return max(tt_proportion)\n",
    "\n",
    "CLEANED_FOLDER = 'sbu_cleaned/'\n",
    "class_i = '05' # shake hands\n",
    "class_i = '02' # moving\n",
    "classes = ['01','02','03','04','05','06','07','08']\n",
    "\n",
    "#classes = ['08']\n",
    "for class_i in classes:\n",
    "    target_folder = os.path.join(CLEANED_FOLDER,class_i)\n",
    "    act_dict, react_dict = build_data_set(target_folder,joint_ind=8,subact_length = 6, show_fag=False)\n",
    "\n",
    "    print act_dict.shape,react_dict.shape\n",
    "    \n",
    "    \n",
    "    training_samples, training_ground, test_samples, test_ground = divide_data_set(act_dict, react_dict)\n",
    "    print 'all:',act_dict.shape[0],'train:',training_samples.shape[0],'test:',test_samples.shape[0]\n",
    "        \n",
    "    config_path = os.path.join(CLEANED_FOLDER,class_i+'_skel_pose_'+\".npz\")\n",
    "    np.savez(config_path, training_samples=training_samples, training_ground=training_ground,\\\n",
    "             test_samples = test_samples, test_ground = test_ground)\n",
    "        \n",
    "    \n",
    "#     from sklearn import svm\n",
    "#     X = training_samples\n",
    "#     y = training_ground\n",
    "#     print X.shape,y.shape\n",
    "#     clf = svm.SVC()\n",
    "#     clf.fit(X,y)\n",
    "#     print sum(clf.predict(test_samples)==test_ground)/float(len(test_ground))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:0.99\tRandom:0.95\tDT:0.98\t\n",
      "KNN:0.98\tRandom:0.98\tDT:0.96\t\n",
      "KNN:0.59\tRandom:0.43\tDT:0.65\t\n",
      "KNN:0.69\tRandom:0.43\tDT:0.70\t\n",
      "KNN:0.59\tRandom:0.43\tDT:0.62\t\n",
      "KNN:0.59\tRandom:0.37\tDT:0.61\t\n",
      "KNN:0.65\tRandom:0.37\tDT:0.67\t\n",
      "KNN:0.63\tRandom:0.48\tDT:0.68\t\n"
     ]
    }
   ],
   "source": [
    "# this part is to compare the different classification method on the data\n",
    "def KNN_test(training_samples, training_ground, test_samples, test_ground):\n",
    "\n",
    "    from sklearn.neighbors import KDTree\n",
    "    kdt = KDTree(training_samples, leaf_size=50, metric='euclidean')\n",
    "\n",
    "    nn_matrix = kdt.query(test_samples, k=15, return_distance=False)\n",
    "\n",
    "    test_results = np.zeros(test_samples.shape[0]).astype('int')\n",
    "    for act_i in range(test_samples.shape[0]):\n",
    "        nn_indices = nn_matrix[act_i]\n",
    "        nn_values = training_ground[nn_indices]\n",
    "        counts = np.bincount(nn_values)\n",
    "        test_results[act_i] = np.argmax(counts)\n",
    "    \n",
    "    return sum(test_results==test_ground)/float(test_results.shape[0])\n",
    "    \n",
    "    count_error = 0\n",
    "    for i in range(test_results.shape[0]):\n",
    "        if test_results[i]>0 and test_ground[i]>0 and test_results[i]<>test_ground[i]:\n",
    "            count_error = count_error+1\n",
    "\n",
    "def DT_test(training_samples, training_ground, test_samples, test_ground):\n",
    "    from sklearn import tree\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(training_samples, training_ground)\n",
    "    test_results = clf.predict(test_samples)\n",
    "    #print test_results\n",
    "    return sum(test_results==test_ground)/float(test_results.shape[0])\n",
    "\n",
    "\n",
    "for class_i in classes:\n",
    "    config_path = os.path.join(CLEANED_FOLDER,class_i+\".npz\")\n",
    "    data = np.load(config_path)\n",
    "    training_samples = data['training_samples']\n",
    "    training_ground = data['training_ground']\n",
    "    test_samples = data['test_samples']\n",
    "    test_ground = data['test_ground']\n",
    "    print \"KNN:{0:.2f}\\t\".format(KNN_test(training_samples, training_ground, test_samples, test_ground)),\n",
    "    print \"Random:{0:.2f}\\t\".format(random_precision(training_ground)),\n",
    "    print \"DT:{0:.2f}\\t\".format(DT_test(training_samples, training_ground, test_samples, test_ground)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tt_proportion = []\n",
    "for i in np.unique(training_ground):\n",
    "    proportion = sum(training_ground==i)/float(len(training_ground))\n",
    "    tt_proportion.extend([proportion])\n",
    "print tt_proportion\n",
    "print max(tt_proportion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torso distance velocity feature:\n",
    "KNN:0.99\tRandom:0.95\tDT:0.97\t\n",
    "KNN:0.98\tRandom:0.98\tDT:0.98\t\n",
    "KNN:0.59\tRandom:0.43\tDT:0.66\t\n",
    "KNN:0.69\tRandom:0.43\tDT:0.65\t\n",
    "KNN:0.59\tRandom:0.43\tDT:0.58\t\n",
    "KNN:0.59\tRandom:0.37\tDT:0.61\t\n",
    "KNN:0.65\tRandom:0.37\tDT:0.70\t\n",
    "KNN:0.63\tRandom:0.48\tDT:0.63\t\n",
    "\n",
    "+skel to react torso distance feature:\n",
    "KNN:0.99\tRandom:0.95\tDT:0.97\t\n",
    "KNN:0.98\tRandom:0.98\tDT:0.98\t\n",
    "KNN:0.59\tRandom:0.43\tDT:0.67\t\n",
    "KNN:0.69\tRandom:0.43\tDT:0.65\t\n",
    "KNN:0.59\tRandom:0.43\tDT:0.62\t\n",
    "KNN:0.59\tRandom:0.37\tDT:0.59\t\n",
    "KNN:0.65\tRandom:0.37\tDT:0.68\t\n",
    "KNN:0.63\tRandom:0.48\tDT:0.63\t\n",
    "\n",
    "+skel to its own torso distance feature:\n",
    "KNN:0.99\tRandom:0.95\tDT:0.98\t\n",
    "KNN:0.98\tRandom:0.98\tDT:0.98\t\n",
    "KNN:0.59\tRandom:0.43\tDT:0.66\t\n",
    "KNN:0.69\tRandom:0.43\tDT:0.66\t\n",
    "KNN:0.59\tRandom:0.43\tDT:0.62\t\n",
    "KNN:0.59\tRandom:0.37\tDT:0.66\t\n",
    "KNN:0.65\tRandom:0.37\tDT:0.69\t\n",
    "KNN:0.63\tRandom:0.48\tDT:0.65\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,3]\n",
    "print a\n",
    "a.extend([2])\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization learned intense\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "import matplotlib.animation as animation\n",
    "# Attaching 3D axis to the figure\n",
    "# main function\n",
    "fn = '/Users/rmqlife/Desktop/CoRL2017/sbu_cleaned/05/s01s02001.txt'\n",
    "\n",
    "\n",
    "def draw_vector(ax,s,e):\n",
    "    subtract = s-e\n",
    "    vlength = np.dot(subtract,subtract)**0.5\n",
    "    print s, e, s-e\n",
    "    print s[2],s[0],s[1]\n",
    "\n",
    "    ax.quiver(s[2],s[0],s[1],e[2],e[0],e[1],length = vlength)\n",
    "    #ax.quiver(start_point[0],start_point[1],start_point[2],end_point[0],end_point[1],end_point[2],length = vlength)\n",
    "\n",
    "def canvas():\n",
    "    fig = plt.figure()\n",
    "    ax = p3.Axes3D(fig)\n",
    "    # Setting the axes properties\n",
    "    ax.set_xlim3d([0.0, 1.0])\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylim3d([0.0, 1.0])\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlim3d([1.0, 0.0])\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title('3D Test')\n",
    "    return fig,ax\n",
    "    \n",
    "def draw_points(ax,points):\n",
    "    ax.scatter(points[:,2],points[:,0],points[:,1])\n",
    "\n",
    "with open(fn,'r') as src_file:\n",
    "    video = src_file.read().splitlines()\n",
    "    \n",
    "    act_subject = get_act_subject(video)\n",
    "        \n",
    "    fig, ax = canvas()\n",
    "    \n",
    "    #ax.scatter(j1z,j1x,j1y)\n",
    "    skel_act = get_skels_by_subject(video,act_subject)\n",
    "    joints_act = get_joints_by_subject(video,act_subject,[5,8])  \n",
    "    joints_react = get_joints_by_subject(video,1-act_subject,[5,8])\n",
    "    \n",
    "\n",
    "    # draw_vector(ax,joints_react[0,:],joints_react[-2,:])    \n",
    "    draw_points(ax, joints_act)\n",
    "    draw_points(ax, joints_react)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a trajectory\n",
    "\n",
    "print 1+2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
